{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dr-Mohamed-Elkholy/Machine-Learning-Projects/blob/main/Deep_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "korean-wednesday",
      "metadata": {
        "id": "korean-wednesday"
      },
      "source": [
        "# Image Classification with Deep Neural Networks\n",
        "You should build an end-to-end machine learning pipeline using a deep learning model. In particular, you should do the following:\n",
        "- Load the `fashion mnist` dataset from [TensorFlow](https://www.tensorflow.org/tutorials/keras/classification). The loaded dataset is already split into training and test sets.\n",
        "- Build an end-to-end machine learning pipeline, including a [deep learning](https://www.tensorflow.org/tutorials/keras/classification) model.\n",
        "- Optimize your pipeline by validating your design decisions.\n",
        "- Test the best pipeline on the test set and report various [evaluation metrics](https://scikit-learn.org/0.15/modules/model_evaluation.html).  \n",
        "- Check the documentation to identify the most important hyperparameters, attributes, and methods of the model. Use them in practice."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the data"
      ],
      "metadata": {
        "id": "apJSrLgiH3EJ"
      },
      "id": "apJSrLgiH3EJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "yYGImjERH8pt"
      },
      "id": "yYGImjERH8pt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "infrared-copper",
      "metadata": {
        "id": "infrared-copper",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9805d9-af72-4285-bce7-6e749864e978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Loading the Fashion MNIST dataset\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# # Normalizing the images to the range of [0., 1.]\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Checking the shape of the datasets\n",
        "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the model"
      ],
      "metadata": {
        "id": "ntB8HLqznXkC"
      },
      "id": "ntB8HLqznXkC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Reshape the data to add a channel dimension\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# Step 3: Build the deep learning model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)), # to identify pattern like edges and textures\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)), # condense or shrink images to 2 * 2\n",
        "    tf.keras.layers.Flatten(), # flatten to line of numberss\n",
        "    tf.keras.layers.Dense(128, activation='relu'), # interprete the pattern\n",
        "    tf.keras.layers.Dense(10, activation='softmax') # like rethink or reclassify\n",
        "])\n",
        "\n",
        "# Step 4: Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model summary to check the structure of the neural network\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "445DUWKcnjuS",
        "outputId": "9c504d3a-c087-4988-ba0a-1456fa812213"
      },
      "id": "445DUWKcnjuS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 13, 13, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 5408)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               692352    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 693962 (2.65 MB)\n",
            "Trainable params: 693962 (2.65 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting"
      ],
      "metadata": {
        "id": "Bor2SpA-olmX"
      },
      "id": "Bor2SpA-olmX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train the model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Create early stopping (stop training after the validation loss has not improved for 5 epochs)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# Include early stopping in the model's fit method\n",
        "history = model.fit(train_images, train_labels, epochs=10, validation_split=0.2, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar4hC_dLooZU",
        "outputId": "ddc2502c-9e38-4a56-8251-be7d82cb7b72"
      },
      "id": "ar4hC_dLooZU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 39s 26ms/step - loss: 0.4098 - accuracy: 0.8545 - val_loss: 0.3116 - val_accuracy: 0.8915\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 36s 24ms/step - loss: 0.2795 - accuracy: 0.9001 - val_loss: 0.2758 - val_accuracy: 0.9005\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 37s 24ms/step - loss: 0.2326 - accuracy: 0.9149 - val_loss: 0.2707 - val_accuracy: 0.9005\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 35s 23ms/step - loss: 0.1989 - accuracy: 0.9267 - val_loss: 0.2521 - val_accuracy: 0.9103\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 37s 25ms/step - loss: 0.1723 - accuracy: 0.9361 - val_loss: 0.2631 - val_accuracy: 0.9063\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 38s 26ms/step - loss: 0.1461 - accuracy: 0.9463 - val_loss: 0.2494 - val_accuracy: 0.9144\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 39s 26ms/step - loss: 0.1274 - accuracy: 0.9530 - val_loss: 0.2750 - val_accuracy: 0.9100\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 34s 23ms/step - loss: 0.1062 - accuracy: 0.9614 - val_loss: 0.2652 - val_accuracy: 0.9141\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 36s 24ms/step - loss: 0.0892 - accuracy: 0.9681 - val_loss: 0.2990 - val_accuracy: 0.9117\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 37s 25ms/step - loss: 0.0758 - accuracy: 0.9721 - val_loss: 0.3212 - val_accuracy: 0.9124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaulation"
      ],
      "metadata": {
        "id": "DXl_a08-shEN"
      },
      "id": "DXl_a08-shEN"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "\n",
        "# Display the test set accuracy\n",
        "print(\"Accuracy on test set:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1C3K3Zashng",
        "outputId": "f5a810ee-d8c8-4edc-b8b4-a99119c9b0e9"
      },
      "id": "u1C3K3Zashng",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5920 - accuracy: 0.9045\n",
            "Accuracy on test set: 0.9045000076293945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ],
      "metadata": {
        "id": "AAgaBB4sszIR"
      },
      "id": "AAgaBB4sszIR"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Predict the values from the test dataset\n",
        "test_predictions = model.predict(test_images)\n",
        "# Convert predictions classes to one hot vectors\n",
        "predicted_classes = np.argmax(test_predictions, axis=1)\n",
        "\n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(test_labels, predicted_classes)\n",
        "\n",
        "\n",
        "\n",
        "# compute classification report\n",
        "classification_report = classification_report(test_labels, predicted_classes, target_names=class_names)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_mtx)\n",
        "print(\"\\nClassification Report:\\n\", classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qD6OF2ts5GK",
        "outputId": "f36c27db-0e3c-49de-f9e6-d60e33e755e7"
      },
      "id": "3qD6OF2ts5GK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 13ms/step\n",
            "Confusion Matrix:\n",
            " [[898   1  21  10   4   1  62   1   2   0]\n",
            " [  2 978   1   8   9   0   1   0   1   0]\n",
            " [ 22   1 882   5  49   0  41   0   0   0]\n",
            " [ 37   4   8 880  37   0  31   0   3   0]\n",
            " [  2   1 101  14 830   1  51   0   0   0]\n",
            " [  2   0   0   0   0 976   0  14   0   8]\n",
            " [143   1  59  19  69   0 701   1   7   0]\n",
            " [  0   0   0   0   0   5   0 966   0  29]\n",
            " [  6   1   5   4   3   2   2   3 973   1]\n",
            " [  2   0   0   0   2   8   1  26   0 961]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.81      0.90      0.85      1000\n",
            "     Trouser       0.99      0.98      0.98      1000\n",
            "    Pullover       0.82      0.88      0.85      1000\n",
            "       Dress       0.94      0.88      0.91      1000\n",
            "        Coat       0.83      0.83      0.83      1000\n",
            "      Sandal       0.98      0.98      0.98      1000\n",
            "       Shirt       0.79      0.70      0.74      1000\n",
            "     Sneaker       0.96      0.97      0.96      1000\n",
            "         Bag       0.99      0.97      0.98      1000\n",
            "  Ankle boot       0.96      0.96      0.96      1000\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.91      0.90      0.90     10000\n",
            "weighted avg       0.91      0.90      0.90     10000\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}